{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f1ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.messages import ModelMessage\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "from pydantic_ai import Agent\n",
    "\n",
    "\n",
    "class PydanticAgent():\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        model: OpenAIModel, \n",
    "        output_type: str,\n",
    "        system_prompt: str = \"You are a helpful assistant.\",\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Create an agent\n",
    "\n",
    "        Args:\n",
    "            agent_id: pydantic_ai.Agent instance\n",
    "        \"\"\"\n",
    "        #self.memory_lst = []\n",
    "        self.name = name\n",
    "        self.agent = Agent(model=model, \n",
    "                           name=name, \n",
    "                           output_type=output_type,\n",
    "                           system_prompt=system_prompt,\n",
    "                           model_settings={'tool_choice': 'auto'}\n",
    "                           )\n",
    "        self.message_history=list[ModelMessage]\n",
    "\n",
    "    def ask(self, question: str) -> str:\n",
    "        result = self.agent.run_sync(\n",
    "            user_prompt=question,\n",
    "            #message_history=message_history,\n",
    "        )\n",
    "\n",
    "\n",
    "        self.message_history=result.all_messages()\n",
    "\n",
    "        return result.output\n",
    "    '''\n",
    "    def add_event(self, event: str):\n",
    "        \"\"\"Add an new event in the memory\n",
    "\n",
    "        Args:\n",
    "            event (str): string that describe the event.\n",
    "        \"\"\"\n",
    "        self.message_history.append({\"role\": \"user\", \"content\": f\"{event}\"})\n",
    "\n",
    "    def _add_memory(self, memory: str):\n",
    "        \"\"\"Monologue in the memory\n",
    "\n",
    "        Args:\n",
    "            memory (str): string that generated by the model in the last round.\n",
    "        \"\"\"\n",
    "        self.message_history.append({\"role\": \"assistant\", \"content\": f\"{memory}\"})\n",
    "        print(f\"----- {self.name} memory: \\n{self.message_history} -----\\n\")\n",
    "\n",
    "    def ask(self, question: str):\n",
    "\n",
    "        answer = self._query(question)\n",
    "        #self._add_memory(answer)\n",
    "        return answer\n",
    "    '''\n",
    "    def get_all_messages(self):\n",
    "        \"\"\"Get the memory of the agent\"\"\"\n",
    "        return self.message_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da017455",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "model = OpenAIModel(\n",
    "    #'Qwen/Qwen3-8B'\n",
    "    model_name='Qwen/Qwen2.5-7B-Instruct',\n",
    "    provider=OpenAIProvider(\n",
    "        base_url='https://api.siliconflow.cn/v1',\n",
    "        api_key='sk-xxx'\n",
    "    ),\n",
    ")\n",
    "\n",
    "play_agent = Agent(model=model, \n",
    "                   name='test', \n",
    "                   output_type=str,\n",
    "                   system_prompt='',\n",
    "                   model_settings={'tool_choice': 'auto'}\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "912d7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from pydantic import BaseModel\n",
    "class DebateEvaluationOut(BaseModel):\n",
    "    \"\"\"\n",
    "    Analyze both sides of the current situation and provide a comprehensive final answer.\n",
    "    \n",
    "    The output should indicate which position is more reasonable and integrate insights from both sides.\n",
    "    \"\"\"\n",
    "\n",
    "    Reason: str \n",
    "    debate_answer: Literal['Affirmative', 'Negative', 'Neutral']\n",
    "    Final_Answer: str \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192fdec9",
   "metadata": {},
   "outputs": [
    {
     "ename": "PydanticSchemaGenerationError",
     "evalue": "Unable to generate pydantic-core schema for [<class 'str'>, <class '__main__.DebateEvaluationOut'>]. Set `arbitrary_types_allowed=True` in the model_config to ignore this error or implement `__get_pydantic_core_schema__` on your type to fully support it.\n\nIf you got this error by calling handler(<some type>) within `__get_pydantic_core_schema__` then you likely need to call `handler.generate_schema(<some type>)` since we do not call `__get_pydantic_core_schema__` on `<some type>` otherwise to avoid infinite recursion.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/schema-for-unknown-type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\type_adapter.py:271\u001b[0m, in \u001b[0;36mTypeAdapter._init_core_attrs\u001b[1;34m(self, ns_resolver, force, raise_errors)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore_schema \u001b[38;5;241m=\u001b[39m \u001b[43m_getattr_no_parents\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m__pydantic_core_schema__\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidator \u001b[38;5;241m=\u001b[39m _getattr_no_parents(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_type, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__pydantic_validator__\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\type_adapter.py:55\u001b[0m, in \u001b[0;36m_getattr_no_parents\u001b[1;34m(obj, attribute)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(attribute)\n",
      "\u001b[1;31mAttributeError\u001b[0m: __pydantic_core_schema__",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mPydanticSchemaGenerationError\u001b[0m             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Union\n\u001b[0;32m     17\u001b[0m Output \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, DebateEvaluationOut]\n\u001b[1;32m---> 19\u001b[0m agent\u001b[38;5;241m=\u001b[39m\u001b[43mAgent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mJudge2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDebateEvaluationOut\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Replace with the correct output_type if needed\u001b[39;49;00m\n\u001b[0;32m     23\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic_ai\\agent.py:320\u001b[0m, in \u001b[0;36mAgent.__init__\u001b[1;34m(self, model, output_type, instructions, system_prompt, deps_type, name, model_settings, retries, output_retries, tools, prepare_tools, mcp_servers, defer_model_check, end_strategy, instrument, **_deprecated_kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`result_retries` is deprecated, use `max_result_retries` instead\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m    318\u001b[0m     output_retries \u001b[38;5;241m=\u001b[39m result_retries\n\u001b[1;32m--> 320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_schema \u001b[38;5;241m=\u001b[39m \u001b[43m_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOutputSchema\u001b[49m\u001b[43m[\u001b[49m\u001b[43mOutputDataT\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deprecated_result_tool_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_deprecated_result_tool_description\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_validators \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_instructions \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic_ai\\_output.py:132\u001b[0m, in \u001b[0;36mOutputSchema.build\u001b[1;34m(cls, output_type, name, description, strict)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     name \u001b[38;5;241m=\u001b[39m name \u001b[38;5;129;01mor\u001b[39;00m DEFAULT_OUTPUT_TOOL_NAME\n\u001b[0;32m    130\u001b[0m     tools[name] \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m    131\u001b[0m         OutputSchemaTool[T],\n\u001b[1;32m--> 132\u001b[0m         \u001b[43mOutputSchemaTool\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_type_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultiple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(tools\u001b[38;5;241m=\u001b[39mtools, allow_text_output\u001b[38;5;241m=\u001b[39mallow_text_output)\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic_ai\\_output.py:191\u001b[0m, in \u001b[0;36mOutputSchemaTool.__init__\u001b[1;34m(self, output_type, name, description, multiple, strict)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     response_data_typed_dict \u001b[38;5;241m=\u001b[39m TypedDict(  \u001b[38;5;66;03m# noqa: UP013\u001b[39;00m\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse_data_typed_dict\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    189\u001b[0m         {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m: output_type},  \u001b[38;5;66;03m# pyright: ignore[reportInvalidTypeForm]\u001b[39;00m\n\u001b[0;32m    190\u001b[0m     )\n\u001b[1;32m--> 191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype_adapter \u001b[38;5;241m=\u001b[39m \u001b[43mTypeAdapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_data_typed_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m     outer_typed_dict_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# noinspection PyArgumentList\u001b[39;00m\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\type_adapter.py:228\u001b[0m, in \u001b[0;36mTypeAdapter.__init__\u001b[1;34m(self, type, config, _parent_depth, module)\u001b[0m\n\u001b[0;32m    225\u001b[0m     localns \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_module_name \u001b[38;5;241m=\u001b[39m module \u001b[38;5;129;01mor\u001b[39;00m cast(\u001b[38;5;28mstr\u001b[39m, globalns\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__name__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m--> 228\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_core_attrs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mns_resolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_namespace_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNsResolver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnamespaces_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_namespace_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNamespacesTuple\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlocals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocalns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mglobals\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mglobalns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparent_namespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocalns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    232\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    234\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\type_adapter.py:290\u001b[0m, in \u001b[0;36mTypeAdapter._init_core_attrs\u001b[1;34m(self, ns_resolver, force, raise_errors)\u001b[0m\n\u001b[0;32m    287\u001b[0m schema_generator \u001b[38;5;241m=\u001b[39m _generate_schema\u001b[38;5;241m.\u001b[39mGenerateSchema(config_wrapper, ns_resolver\u001b[38;5;241m=\u001b[39mns_resolver)\n\u001b[0;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 290\u001b[0m     core_schema \u001b[38;5;241m=\u001b[39m \u001b[43mschema_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m PydanticUndefinedAnnotation:\n\u001b[0;32m    292\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_errors:\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:610\u001b[0m, in \u001b[0;36mGenerateSchema.generate_schema\u001b[1;34m(self, obj, from_dunder_get_core_schema)\u001b[0m\n\u001b[0;32m    607\u001b[0m         schema \u001b[38;5;241m=\u001b[39m from_property\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 610\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    612\u001b[0m metadata_js_function \u001b[38;5;241m=\u001b[39m _extract_get_pydantic_json_schema(obj, schema)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m metadata_js_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:884\u001b[0m, in \u001b[0;36mGenerateSchema._generate_schema_inner\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdefinition_reference_schema(schema_ref\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mtype_ref)\n\u001b[1;32m--> 884\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:956\u001b[0m, in \u001b[0;36mGenerateSchema.match_type\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_literal_schema(obj)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_typeddict(obj):\n\u001b[1;32m--> 956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_typed_dict_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _typing_extra\u001b[38;5;241m.\u001b[39mis_namedtuple(obj):\n\u001b[0;32m    958\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_namedtuple_schema(obj, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:1462\u001b[0m, in \u001b[0;36mGenerateSchema._typed_dict_schema\u001b[1;34m(self, typed_dict_cls, origin)\u001b[0m\n\u001b[0;32m   1460\u001b[0m         field_info\u001b[38;5;241m.\u001b[39mdescription \u001b[38;5;241m=\u001b[39m field_docstrings[field_name]\n\u001b[0;32m   1461\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_field_title_generator_to_field_info(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config_wrapper, field_info, field_name)\n\u001b[1;32m-> 1462\u001b[0m     fields[field_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_td_field_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1463\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequired\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequired\u001b[49m\n\u001b[0;32m   1464\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1466\u001b[0m td_schema \u001b[38;5;241m=\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mtyped_dict_schema(\n\u001b[0;32m   1467\u001b[0m     fields,\n\u001b[0;32m   1468\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39mtyped_dict_cls,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1474\u001b[0m     config\u001b[38;5;241m=\u001b[39mcore_config,\n\u001b[0;32m   1475\u001b[0m )\n\u001b[0;32m   1477\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_model_serializers(td_schema, decorators\u001b[38;5;241m.\u001b[39mmodel_serializers\u001b[38;5;241m.\u001b[39mvalues())\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:1054\u001b[0m, in \u001b[0;36mGenerateSchema._generate_td_field_schema\u001b[1;34m(self, name, field_info, decorators, required)\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_td_field_schema\u001b[39m(\n\u001b[0;32m   1046\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1047\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1051\u001b[0m     required: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   1052\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mTypedDictField:\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Prepare a TypedDictField to represent a model or typeddict field.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1054\u001b[0m     common_field \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_common_field_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfield_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecorators\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1055\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mtyped_dict_field(\n\u001b[0;32m   1056\u001b[0m         common_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mschema\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   1057\u001b[0m         required\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m field_info\u001b[38;5;241m.\u001b[39mis_required() \u001b[38;5;28;01melse\u001b[39;00m required,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1061\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mcommon_field[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m   1062\u001b[0m     )\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:1263\u001b[0m, in \u001b[0;36mGenerateSchema._common_field_schema\u001b[1;34m(self, name, field_info, decorators)\u001b[0m\n\u001b[0;32m   1259\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_annotations(\n\u001b[0;32m   1260\u001b[0m             source_type, annotations \u001b[38;5;241m+\u001b[39m validators_from_decorators, transform_inner_schema\u001b[38;5;241m=\u001b[39mset_discriminator\n\u001b[0;32m   1261\u001b[0m         )\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1263\u001b[0m         schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_annotations\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1264\u001b[0m \u001b[43m            \u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1265\u001b[0m \u001b[43m            \u001b[49m\u001b[43mannotations\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalidators_from_decorators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1266\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1268\u001b[0m \u001b[38;5;66;03m# This V1 compatibility shim should eventually be removed\u001b[39;00m\n\u001b[0;32m   1269\u001b[0m \u001b[38;5;66;03m# push down any `each_item=True` validators\u001b[39;00m\n\u001b[0;32m   1270\u001b[0m \u001b[38;5;66;03m# note that this won't work for any Annotated types that get wrapped by a function validator\u001b[39;00m\n\u001b[0;32m   1271\u001b[0m \u001b[38;5;66;03m# but that's okay because that didn't exist in V1\u001b[39;00m\n\u001b[0;32m   1272\u001b[0m this_field_validators \u001b[38;5;241m=\u001b[39m filter_field_decorator_info_by_field(decorators\u001b[38;5;241m.\u001b[39mvalidators\u001b[38;5;241m.\u001b[39mvalues(), name)\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2056\u001b[0m, in \u001b[0;36mGenerateSchema._apply_annotations\u001b[1;34m(self, source_type, annotations, transform_inner_schema)\u001b[0m\n\u001b[0;32m   2051\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   2052\u001b[0m     get_inner_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_wrapped_inner_schema(\n\u001b[0;32m   2053\u001b[0m         get_inner_schema, annotation, pydantic_js_annotation_functions\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[1;32m-> 2056\u001b[0m schema \u001b[38;5;241m=\u001b[39m \u001b[43mget_inner_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pydantic_js_annotation_functions:\n\u001b[0;32m   2058\u001b[0m     core_metadata \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\_internal\\_schema_generation_shared.py:84\u001b[0m, in \u001b[0;36mCallbackGetCoreSchemaHandler.__call__\u001b[1;34m(self, source_type)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, source_type: Any, \u001b[38;5;241m/\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m core_schema\u001b[38;5;241m.\u001b[39mCoreSchema:\n\u001b[1;32m---> 84\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     85\u001b[0m     ref \u001b[38;5;241m=\u001b[39m schema\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ref_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto-def\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2037\u001b[0m, in \u001b[0;36mGenerateSchema._apply_annotations.<locals>.inner_handler\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m   2035\u001b[0m from_property \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_schema_from_property(obj, source_type)\n\u001b[0;32m   2036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_property \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2037\u001b[0m     schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_schema_inner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2039\u001b[0m     schema \u001b[38;5;241m=\u001b[39m from_property\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:884\u001b[0m, in \u001b[0;36mGenerateSchema._generate_schema_inner\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, PydanticRecursiveRef):\n\u001b[0;32m    882\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m core_schema\u001b[38;5;241m.\u001b[39mdefinition_reference_schema(schema_ref\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mtype_ref)\n\u001b[1;32m--> 884\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:995\u001b[0m, in \u001b[0;36mGenerateSchema.match_type\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arbitrary_types:\n\u001b[0;32m    994\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arbitrary_type_schema(obj)\n\u001b[1;32m--> 995\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_unknown_type_schema\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:513\u001b[0m, in \u001b[0;36mGenerateSchema._unknown_type_schema\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_unknown_type_schema\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m CoreSchema:\n\u001b[1;32m--> 513\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticSchemaGenerationError(\n\u001b[0;32m    514\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnable to generate pydantic-core schema for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    515\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSet `arbitrary_types_allowed=True` in the model_config to ignore this error\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    516\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or implement `__get_pydantic_core_schema__` on your type to fully support it.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    517\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you got this error by calling handler(<some type>) within\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    518\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m `__get_pydantic_core_schema__` then you likely need to call\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    519\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m `handler.generate_schema(<some type>)` since we do not call\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    520\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m `__get_pydantic_core_schema__` on `<some type>` otherwise to avoid infinite recursion.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    521\u001b[0m     )\n",
      "\u001b[1;31mPydanticSchemaGenerationError\u001b[0m: Unable to generate pydantic-core schema for [<class 'str'>, <class '__main__.DebateEvaluationOut'>]. Set `arbitrary_types_allowed=True` in the model_config to ignore this error or implement `__get_pydantic_core_schema__` on your type to fully support it.\n\nIf you got this error by calling handler(<some type>) within `__get_pydantic_core_schema__` then you likely need to call `handler.generate_schema(<some type>)` since we do not call `__get_pydantic_core_schema__` on `<some type>` otherwise to avoid infinite recursion.\n\nFor further information visit https://errors.pydantic.dev/2.10/u/schema-for-unknown-type"
     ]
    }
   ],
   "source": [
    "model = OpenAIModel(\n",
    "    #'Qwen/Qwen3-8B'\n",
    "    model_name='Qwen/Qwen2.5-7B-Instruct',\n",
    "    provider=OpenAIProvider(\n",
    "        base_url='https://api.siliconflow.cn/v1',\n",
    "        api_key='sk-xxx'\n",
    "    ),\n",
    ")\n",
    "\n",
    "class Box(BaseModel):\n",
    "    width: int\n",
    "    height: int\n",
    "    depth: int\n",
    "    units: str\n",
    "from typing import Union\n",
    "\n",
    "Output = Union[str, DebateEvaluationOut]\n",
    "\n",
    "agent=Agent(\n",
    "    model=model, \n",
    "    name='Judge2',\n",
    "    output_type=Union[str, DebateEvaluationOut],  # Replace with the correct output_type if needed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eaeccac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "make_signature() missing 1 required positional argument: 'signature'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mconfig4prompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m judge_prompt_final2\n\u001b[0;32m     12\u001b[0m dspy\u001b[38;5;241m.\u001b[39mconfigure(lm\u001b[38;5;241m=\u001b[39mlm)\n\u001b[1;32m---> 13\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[43mdspy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSignature\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mplease carefully analyze the current situation. You should consider both supporting and opposing factors or arguments, and evaluate which side is more convincing.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     15\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m classify \u001b[38;5;241m=\u001b[39m dspy\u001b[38;5;241m.\u001b[39mPredict(signature)\n",
      "File \u001b[1;32md:\\Users\\bigdata\\anaconda3\\envs\\pyautogen\\Lib\\site-packages\\dspy\\signatures\\signature.py:44\u001b[0m, in \u001b[0;36mSignatureMeta.__call__\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):  \u001b[38;5;66;03m# noqa: ANN002\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Signature:\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;66;03m# We don't create an actual Signature instance, instead, we create a new Signature class.\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmake_signature\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: make_signature() missing 1 required positional argument: 'signature'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import dspy\n",
    "# 初始化语言模型\n",
    "lm = dspy.LM(\n",
    "    model='openai/Qwen/Qwen2.5-7B-Instruct',\n",
    "    api_key='sk-xxx',\n",
    "    api_base='https://api.siliconflow.cn/v1',\n",
    ")\n",
    "from config4prompt import judge_prompt_final2\n",
    "dspy.configure(lm=lm)\n",
    "signature = dspy.Signature(\"debate_topic -> supported_side: Literal['Affirmative', 'Negative']\", instructions=\"please carefully analyze the current situation. You should consider both supporting and opposing factors or arguments, and evaluate which side is more convincing.\")\n",
    "\n",
    "classify = dspy.Predict(signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f29351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Affirmative\n"
     ]
    }
   ],
   "source": [
    "answer=classify(debate_topic=judge_prompt_final2)\n",
    "print(answer.supported_side)\n",
    "context=lm.history[-1] if lm.history else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8c9f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional,Union\n",
    "\n",
    "class Evaluator:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        model: str,\n",
    "        api_key: str ,\n",
    "        api_base: str,\n",
    "        signature: str,\n",
    "        instructions: Optional[str] = None,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Initialize a classification agent that uses DSPy to classify questions.\n",
    "\n",
    "        Args:\n",
    "            model (Agent): The model name or configuration.\n",
    "            api_key (str): API key for the language model service.\n",
    "            api_base (Optional[str]): Base URL for the API (e.g., Azure or custom OpenAI endpoint).\n",
    "        \"\"\"\n",
    "        # 初始化语言模型\n",
    "        self.lm = dspy.LM(\n",
    "            model=model,\n",
    "            api_key=api_key,\n",
    "            api_base=api_base\n",
    "        )\n",
    "        self.signature = signature\n",
    "        self.instructions = instructions\n",
    "        self.name = name if name is not None else 'Evaluator'\n",
    "        # 设置全局默认语言模型\n",
    "        # dspy.settings.configure(lm=self.lm )\n",
    "\n",
    "    def run(self, **kwargs) -> str:\n",
    "        \"\"\"\n",
    "        Classifies the given question using a DSPy Predict module.\n",
    "\n",
    "        Args:\n",
    "            question (str): Input question to be classified.\n",
    "\n",
    "        Returns:\n",
    "            str: Classification result.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with dspy.context(lm = self.lm): \n",
    "                signature = dspy.Signature(signature=self.signature, instructions=self.instructions)\n",
    "                classify = dspy.Predict(signature)\n",
    "                print(classify)\n",
    "                result = classify(**kwargs)\n",
    "                return result # 假设返回结果字段是 answer\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during classification: {e}\")\n",
    "            return \"unknown\"\n",
    "\n",
    "signature=\"debate_text -> supported_side: Literal['Affirmative', 'Negative']\"\n",
    "instructions=\"please carefully analyze the current situation. You should consider both supporting and opposing factors or arguments, and evaluate which side is more convincing.\"\n",
    "evaluator = Evaluator(#model='openai/Qwen/Qwen2.5-32B-Instruct', \n",
    "                        name='Judge2',\n",
    "                        model='openai/Qwen/Qwen2.5-7B-Instruct',\n",
    "                        api_key='sk-xxx', \n",
    "                        api_base='https://api.siliconflow.cn/v1',\n",
    "                        signature=signature,\n",
    "                        instructions= instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "974d058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict(StringSignature(debate_text -> supported_side\n",
      "    instructions='please carefully analyze the current situation. You should consider both supporting and opposing factors or arguments, and evaluate which side is more convincing.'\n",
      "    debate_text = Field(annotation=str required=True json_schema_extra={'__dspy_field_type': 'input', 'prefix': 'Debate Text:', 'desc': '${debate_text}'})\n",
      "    supported_side = Field(annotation=Literal['Affirmative', 'Negative'] required=True json_schema_extra={'__dspy_field_type': 'output', 'prefix': 'Supported Side:', 'desc': '${supported_side}'})\n",
      "))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction(\n",
       "    supported_side='Affirmative'\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "debate_text='''[[ ## debate_text ## ]]\n",
    "\n",
    "[[ ## debate_topic ## ]]\n",
    "仔细分析现在的经济情况\n",
    "\n",
    "[[ ## affirmative_side_arguing ## ]]\n",
    "我同意你的分析，并认为你所提出的观点非常具有针对性和深度。你的分析不仅指出了当前经济环境下的一些关键问题，还提出了合理的政策建议。让我们进一步探讨和细化这些观点：\n",
    "\n",
    "### 1. **经济增长**\n",
    "\n",
    "**现状分析：**\n",
    "- **发达国家**：确实，美国等国家在低通胀和高就业率下表现相对稳定，但也不能忽视欧洲等地区面临的下行压力。德国的表现确实为其他欧洲国家提供了一些借鉴。\n",
    "- **新兴市场与发展中国家**：你提到东南亚国家的经济增长速度较高，这是值得肯定的亮点，但也需要关注这些国家的长期可持续性。\n",
    "\n",
    "**问题与挑战：**\n",
    "- 政策支持和行业合作对于技术创新和产业升级确实至关重要。可以进一步探讨政府如何通过税收减免、研发补贴等方式激励企业和研究机构。\n",
    "- 疫后恢复确实有进展，但建议从更长远的角度考虑稳定经济复苏的因素，例如持续的投资和支持基础设施建设，以及针对不同地区的特殊政策。\n",
    "\n",
    "### 2. **通胀**\n",
    "\n",
    "**现状分析：**\n",
    "- 你强调了一些欠发达国家通胀相对温和，这需要进一步分析这些国家的具体政策和市场因素。同时，西方高通胀确实由多重因素共同作用。\n",
    "\n",
    "**问题与挑战：**\n",
    "- 你说得对，不同国家的情况确实复杂。应对对策可以包括分阶段、有针对性的货币政策调整。例如，美国可以通过减少过剩流动性来应对通胀。\n",
    "- 通过结构性改革和解决问题的瓶颈措施，可以缓解通胀对消费预期的影响。此外，推动市场竞争可以减少通胀压力。\n",
    "\n",
    "### 3. **就业**\n",
    "\n",
    "**现状分析：**\n",
    "- 生态失衡和技能差距确实是当前就业市场面临的重要问题。你提到通过教育和培训体系来缓解青年就业问题是一个很好的切入点。\n",
    "- 建立创业政策确实可以创造更多就业机会，但这需要更多具体的政策措施来支持创业者的起步和发展。\n",
    "\n",
    "### 4. **金融市场**\n",
    "\n",
    "**现状分析：**\n",
    "- 股市确实存在泡沫迹象，特别是在科技股。你说的监管和引导民众投资的行为非常重要。\n",
    "- 债务风险上升在部分新兴市场的确是一个重要问题。加强金融监管和风险管理的关键在于提高透明度和建立健全的金融体系。\n",
    "\n",
    "**问题与挑战：**\n",
    "- 引导市场预期和行为确实需要监管机构和市场的共同努力。例如，通过信息披露机制和投资者教育来增强市场信息对称性。\n",
    "- 加强新兴市场的监管能力不仅需要内部改革，还需要国际间的协作和支持。\n",
    "\n",
    "### 5. **国际贸易**\n",
    "\n",
    "**现状分析：**\n",
    "- 保护主义的抬头确实需要警惕，同时也反映出一些国家对经济依赖的担忧。推动区域经济一体化是一个积极的路径，但需要成员国之间的深度合作。\n",
    "\n",
    "**问题与挑战：**\n",
    "- 建立灵活的紧急应变机制可以缓解供应链风险。例如，通过跨国合作，建立更加安全的供应链系统。\n",
    "- 区域经济一体化确实有潜力缓解贸易保护主义的影响，但在执行过程中需要解决实际存在的问题和障碍。可以推动建立双边或多边自贸协定，加强信息共享和合作机制。\n",
    "\n",
    "### 结论\n",
    "\n",
    "我认为你的分析非常全面，并且提出了针对性的政策建议。进一步强调以下几点可以帮助我们更精准地应对当前经济形势：\n",
    "\n",
    "1. **政策的灵活性和针对性**：不同国家和地区的具体情况差异很大，需要根据实际情况调整政策。\n",
    "2. **结构性改革的持续性**：着眼长远，通过结构性改革提升经济的韧性和可持续性。\n",
    "3. **国际合作的重要性**：在全球化背景下，国际合作是解决许多经济问题的关键。\n",
    "\n",
    "综上所述，我完全同意你的分析，并强烈赞同你提出的观点和建议。\n",
    "\n",
    "[[ ## negative_side_arguing ## ]]\n",
    "我非常同意你的进一步分析和建议，你提出了许多有针对性的见解和具体的政策措施，使我们的讨论更加深入和全面。以下是我的进一步分析和观点：\n",
    "\n",
    "### 1. **经济增长**\n",
    "\n",
    "**政策建议：**\n",
    "- **长期可持续性**：针对新兴市场和发展中国家，除了强调短期内的增长速度外，更应关注其长期的经济可持续性。政府可以提供更多关于投资基础设施、技术创新和绿色经济的激励措施，以确保经济增长的长期稳定性。\n",
    "- **政策灵活性**：根据不同国家和地区的情况，灵活调整政策工具和政策重点，如德国成功的做法可以为其他国家提供借鉴。政府可以设立专项基金支持创新和研发，提供税收减免来鼓励企业和研究机构。\n",
    "\n",
    "### 2. **通胀**\n",
    "\n",
    "**政策建议：**\n",
    "- **分阶段调整货币政策**：根据不同的国家和地区，分阶段调整货币政策。例如，对于美国可以通过减少过剩流动性来应对通胀，但需要结合市场实际情况和经济指标进行实时调整。\n",
    "- **结构性改革**：通过提高市场竞争、降低生产成本和提高产业效率来缓解通胀压力。政府可以推出政策措施，促进产业结构优化和提高各行业效率，例如通过国家支持的中小企业发展计划，提高市场的整体竞争力。\n",
    "\n",
    "### 3. **就业**\n",
    "\n",
    "**政策建议：**\n",
    "- **教育与培训体系**：建立更完善的教育和培训体系，尤其是针对青年就业问题。政府可以提供职业培训、实习机会和技能认证项目，以帮助青年适应“新经济”中对高技能劳动力的需求。\n",
    "- **创业政策支持**：进一步完善创业支持政策，包括提供资金、咨询和服务支持，以帮助创业者解决起步和发展中的实际问题。例如，通过政府基金、税收优惠和其他金融工具来扶持初创企业和小微企业。\n",
    "\n",
    "### 4. **金融市场**\n",
    "\n",
    "**政策建议：**\n",
    "- **市场预期管理**：政府和监管机构应共同努力，通过透明的信息披露、加强市场教育和监管来引导市场的合理预期。例如，定期发布市场报告和经济数据，增强市场的信息对称性。\n",
    "- **风险控制机制**：建立更加完善的金融监管体系，包括风险预警系统和应急运作机制。此外，推动金融科技创新，如区块链和人工智能技术的应用，提高金融市场的透明度和效率。\n",
    "\n",
    "### 5. **国际贸易**\n",
    "\n",
    "**政策建议：**\n",
    "- **区域经济一体化**：推动成员国之间的深度合作，解决实际存在的问题和障碍。通过建立双边或多边自贸协定，加强信息共享和合作机制。\n",
    "- **灵活应变机制**：建立更加灵活的供应链系统，通过跨国合作来确保供应链安全。例如，建立多通道物流系统，减少单一依赖性，提高供应链的韧性和抗冲击能力。\n",
    "\n",
    "### 综合结论\n",
    "\n",
    "你的建议和观点非常全面，并且提出了具体的政策措施来应对当前复杂的经济形势。我们可以通过以下几方面来更精准地应对当前的经济问题：\n",
    "1. **灵活调整政策以适应不同国家和地区具体情况**：确保政策措施的有效性和针对性。\n",
    "2. **持续的结构性改革**：提升经济的韧性和可持续性，关注长期稳定性问题。\n",
    "3. **加强国际合作**：在全球化背景下，国际合作对于解决许多经济问题至关重要，特别是在应对贸易保护主义和国际金融风险方面。\n",
    "\n",
    "总结来说，你的建议不仅提供了具体的措施，还提出了更具操作性和前瞻性的策略，使得我们的经济政策更加全面和有效。\n",
    "\n",
    "Respond with the corresponding output fields, starting with the field `[[ ## supported_side ## ]]` (must be formatted as a valid Python Literal[\\'Affirmative\\', \\'Negative\\']), and then ending with the marker for `[[ ## completed ## ]]`.'''\n",
    "\n",
    "\n",
    "evaluator.run(debate_text=debate_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1a04b",
   "metadata": {},
   "source": [
    "## 工具使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0140f12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这里有几条关于传染病的最新新闻：\n",
      "\n",
      "1. 标题: Northwestern Indiana 男子分享与 HIV 相关的故事 - 芝加哥论坛报\n",
      "   链接: [As HIV research gutted at federal level, Northwest Indiana man shares his HIV story - Chicago Tribune](https://www.chicagotribune.com/2025/06/29/as-hiv-research-gutted-at-federal-level-nwi-man-shares-his-hiv-story/)\n",
      "   内容总结: 这位名叫 Gregson 的男子讲述了他的 HIV 诊断经历，包括他如何在诊断后积极面对这一挑战，并表达了对于联邦政府减少资金支持 HIV/AIDS 研究的担忧。 \n",
      "\n",
      "这条新闻详细描述了一个西北伊利诺伊州的男子与 HIV 相关的亲身经历以及他对于目前资金削减给相关研究带来影响的看法。\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import os\n",
    "from pydantic_ai.agent import Agent\n",
    "from pydantic_ai.common_tools.tavily import tavily_search_tool\n",
    "\n",
    "api_key = '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'\n",
    "\n",
    "from pydantic_ai.providers.openai import OpenAIProvider\n",
    "from pydantic_ai.models.openai import OpenAIModel\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "assert api_key is not None\n",
    "\n",
    "model = OpenAIModel(\n",
    "    #'Qwen/Qwen3-8B'\n",
    "    model_name='Qwen/Qwen2.5-7B-Instruct',\n",
    "    provider=OpenAIProvider(\n",
    "        base_url='https://api.siliconflow.cn/v1',\n",
    "        api_key='sk-xxx'\n",
    "    ),\n",
    ")\n",
    "\n",
    "agent = Agent(\n",
    "    model=model,\n",
    "    tools=[tavily_search_tool(api_key)],\n",
    "    system_prompt='Search Tavily for the given query and return the results.',\n",
    ")\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "result = agent.run_sync('告诉我传染病相关最新的头条新闻，给我链接。')\n",
    "print(result.output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec8465db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "根据您的要求，这是最近的关于传染病的头条新闻：\n",
      "\n",
      "1. 标题：As HIV research gutted at federal level, Northwest Indiana man shares his HIV story - [芝加哥论坛报](https://www.chicagotribune.com/2025/06/29/as-hiv-research-gutted-at-federal-level-nwi-man-shares-his-hiv-story/)\n",
      "2. 标题：我与著名作家发生了性关系。我们的邂逅让我深感不安 - [AOL](https://www.aol.com/had-sex-famous-writer-encounter-122455251.html)\n",
      "3. 标题：非洲人类与牲畜界面的抗菌素耐药性传播推断的系统评价 - [自然](https://www.nature.com/articles/s44259-025-00126-y)\n",
      "4. 标题：常规在养猪场使用抗菌素预防相关的多重耐药性风险 - [自然](https://www.nature.com/articles/s44259-025-00130-2)\n",
      "5. 标题：受僵尸真菌感染的飞虫可能生活在恐龙时代 - [CNN](https://www.cnn.com/2025/06/29/science/zombie-fungi-fossil-science-newsletter-wt) \n",
      "\n",
      "您可以点击链接查看详细内容。\n"
     ]
    }
   ],
   "source": [
    "from pydantic_ai import Agent,  ToolOutput\n",
    "\n",
    "from typing import TypeVar\n",
    "from pydantic_ai.messages import ModelMessage, ModelRequest, ModelRequestPart, ModelResponse, TextPart, UserPromptPart\n",
    "from collections.abc import  Sequence\n",
    "from pydantic_ai.tools import Tool, ToolFuncEither, AgentDepsT\n",
    "OutputDataT = TypeVar(\"OutputDataT\")\n",
    "\n",
    "class PydanticAgent():\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        model: OpenAIModel, \n",
    "        output_type: type[OutputDataT] | ToolOutput[OutputDataT],\n",
    "        system_prompt: str = \"You are a helpful assistant.\",\n",
    "        tools: Sequence[\n",
    "            Tool[AgentDepsT] | ToolFuncEither[AgentDepsT, ...]\n",
    "        ] = (),\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Create an agent\n",
    "\n",
    "        \"\"\"\n",
    "        #self.memory_lst = []\n",
    "        self.name = name\n",
    "        \n",
    "        # 判断的是历史all_messages()的context上下文内容\n",
    "        def completion_detector_hook(messages: list[ModelMessage]) -> list[ModelMessage]:  \n",
    "            \"\"\"检测完成标记并处理任务结束\"\"\"  \n",
    "            for message in messages:  \n",
    "                #print (f\">>>> message:  {message} <<<<\")\n",
    "                if isinstance(message, ModelResponse):  \n",
    "                    for part in message.parts:  \n",
    "                        #print (f\">>>> Part:  {part} <<<<\")\n",
    "                        if isinstance(part, TextPart) and part.content.strip() == \"[[ ## completed ## ]]\":  \n",
    "                            # 找到完成标记，可以在这里添加结束逻辑  \n",
    "                            # 例如：抛出自定义异常来停止执行  \n",
    "                            print(\"任务已完成.........\")\n",
    "                            raise TaskCompletedException(\"任务已完成\")\n",
    "\n",
    "            return messages\n",
    "        \n",
    "        class TaskCompletedException(Exception):  \n",
    "            \"\"\"任务完成异常\"\"\"  \n",
    "            pass\n",
    "\n",
    "        self.agent = Agent(model=model, \n",
    "                           name=name, \n",
    "                           output_type=output_type,\n",
    "                           system_prompt=system_prompt,\n",
    "                           tools=tools,\n",
    "                           model_settings={'tool_choice': 'auto'},\n",
    "                           retries=3,\n",
    "                           #history_processors=[completion_detector_hook]\n",
    "                           )\n",
    "    \n",
    "        self.message_history: list[ModelMessage] = []\n",
    "        self.last_answer=''\n",
    "\n",
    "    def ask(self, question: str, reset_history=True, max_msg:int=10) -> str:\n",
    "        \n",
    "        if self.message_history == None or reset_history==True:\n",
    "            result = self.agent.run_sync(\n",
    "            user_prompt=question,\n",
    "        )\n",
    "        else:\n",
    "            result = self.agent.run_sync(\n",
    "            user_prompt=question,\n",
    "            message_history= self.message_history[-max_msg:] if len(self.message_history) > max_msg else self.message_history\n",
    "        )\n",
    "\n",
    "        self.message_history=result.all_messages()\n",
    "        self.last_answer=result.output\n",
    "        \n",
    "        return result.output\n",
    "\n",
    "    def get_all_messages(self):\n",
    "        \"\"\"Get the memory of the agent\"\"\"\n",
    "        return self.message_history\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent = PydanticAgent(\n",
    "        name='test',\n",
    "        model=model,\n",
    "        tools=[tavily_search_tool(api_key)],\n",
    "        system_prompt='Search Tavily for the given query and return the results.',\n",
    "        output_type=str\n",
    "    )\n",
    "\n",
    "    import nest_asyncio\n",
    "    nest_asyncio.apply()\n",
    "\n",
    "    result = agent.ask('告诉我传染病相关最新的头条新闻，给我链接。')\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c8bf5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m nest_asyncio\u001b[38;5;241m.\u001b[39mapply()\n\u001b[0;32m     21\u001b[0m result \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mask(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m告诉我传染病相关最新的头条新闻，给我链接。\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'output'"
     ]
    }
   ],
   "source": [
    "agent = PydanticAgent(\n",
    "    name='test',\n",
    "    model=model,\n",
    "    tools=[tavily_search_tool(api_key)],\n",
    "    system_prompt='Search Tavily for the given query and return the results.',\n",
    "    output_type=str\n",
    ")\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "result = agent.ask('告诉我传染病相关最新的头条新闻，给我链接。')\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc01ccc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这里有一些关于传染病的最新新闻：\n",
      "\n",
      "1. \"As HIV research gutted at federal level, Northwest Indiana man shares his HIV story\" - [Chicago Tribune](https://www.chicagotribune.com/2025/06/29/as-hiv-research-gutted-at-federal-level-nwi-man-shares-his-hiv-story/)\n",
      "2. \"A systematic review of antimicrobial resistance transmission inferences at the human-livestock interface in Africa\" - [Nature](https://www.nature.com/articles/s44259-025-00126-y)\n",
      "3. \"Risk of multidrug resistance in Escherichia coli associated with routine antimicrobial prophylaxis on pig farms\" - [Nature](https://www.nature.com/articles/s44259-025-00130-2)\n",
      "\n",
      "这些文章可能会对你有帮助。\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyautogen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
